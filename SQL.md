# Базы данных & SQL
* ### [Оптимизация запросов: EXPLAIN](#оптимизация-запросов-explain)
* ### [Классификация первичных ключей (Primary Keys)](#Классификация-первичных-ключей-Primary-Keys)
* ### [Управление типом связи через ограничения (Constraints)](#Управление-типом-связи-через-ограничения-Constraints)
* ### [Выбор стратегии хранения связи: Column vs Join Table](#Выбор-стратегии-хранения-связи-Column-vs-Join-Table)
* ### [Шардирование (Sharding)](#Шардирование-Sharding)
* ### [Работа с последовательностями (Sequences)](#работа-с-последовательностями-Sequences)
* ### [Сравнение суррогатных ключей: BIGINT против UUID](#Сравнение-суррогатных-ключей-BIGINT-против-UUID)

## Оптимизация запросов: EXPLAIN

> **Ключевой момент:** Оптимизация начинается не с переписывания кода, а с чтения плана запроса. БД сама говорит тебе, где ей "больно".

### Разница между EXPLAIN и ANALYZE
*   **EXPLAIN:** БД строит план выполнения на основе накопленной статистики (сколько строк в таблице, насколько данные уникальны). Запрос **не выполняется**.
*   **ANALYZE:** БД реально **выполняет** запрос и замеряет время.
*   *Зачем оба:* Чтобы сравнить `Expected Rows` (сколько БД ожидала найти) и `Actual Rows` (сколько нашла на самом деле). Если разница в 10-100 раз — статистика БД "протухла", индексы могут работать неэффективно (analyze обновляет стат. информацию).

### Виды чтений (Сканирования) 

| Тип сканирования | Описание | Когда "возбудиться" (Ctrl+F) |
| :--- | :--- | :--- |
| **Seq Scan** | Чтение всей таблицы подряд. | Если таблица большая (>10к строк), а мы ждем скорости. |
| **Index Scan** | БД идет в индекс, находит адрес строки, а потом идет за данными в таблицу (Heap). | Если данных много, а Index Scan все равно медленный (много случайного чтения). |
| **Index Only Scan** | **Идеал.** Все данные уже есть в индексе. БД вообще не лезет в таблицу. | Добиваемся этого через `COVERING INDEX` (INCLUDE). |
| **Bitmap Index Scan** | "Умный" индекс. Сначала находит все нужные страницы в памяти, строит карту и читает их пачкой. | Часто встречается при сложных условиях `AND/OR`. |

### Covering Index (Покрывающий индекс)
Позволяет добиться **Index Only Scan**.
`CREATE INDEX idx_user_email ON users(name) INCLUDE (email);`
*   **Суть:** Мы добавляем `email` в "тело" индекса по имени. При запросе `SELECT email WHERE name = ...` база вообще не обращается к файлу таблицы, забирая всё из индекса.

### Виды соединений (Joins)

### Nested Loop Join (Вложенный цикл)
*   **Алгоритм:** Для каждой строки из внешней таблицы база сканирует внутреннюю таблицу.
*   **Пример:** 10 заказов и 1 млн пользователей. Если по `user_id` есть индекс, база просто 10 раз быстро прыгнет в индекс.
*   **Минус:** Если индекса нет, база сделает 10 млн проверок.

Ищем заказы пользователя по его ID:

`EXPLAIN ANALYZE SELECT * FROM orders o JOIN users u ON o.user_id = u.id WHERE o.id = 100;`

План выполнения:

```text
Nested Loop  (cost=0.58..16.62 rows=1 actual time=0.034..0.036 loops=1)
  ->  Index Scan using orders_pkey on orders o  (cost=0.29..8.30 rows=1 actual time=0.013..0.014 loops=1)
        Index Cond: (id = 100)
  ->  Index Scan using users_pkey on users u  (cost=0.29..8.30 rows=1 actual time=0.015..0.015 loops=1)
        Index Cond: (id = o.user_id)
Planning Time: 0.154 ms
Execution Time: 0.082 ms
```

* **Внешняя петля**: База идет в таблицу orders по индексу (Primary Key) и находит ОДИН заказ с ID=100.
* **Внутренняя петля**: Берет user_id из этого заказа (например, 5) и идет в таблицу users. Там она мгновенно находит пользователя с ID=5 через его индекс (Primary Key).
* **Итог**: Сделано всего два быстрых прыжка по индексам.

### Hash Join (Хэш-таблица)
*   **Алгоритм:**
1. БД выбирает меньшую таблицу и строит по ней **Hash Map** в оперативной памяти.
2. Затем сканирует большую таблицу и мгновенно (за $O(1)$) ищет совпадения в этой мапе.
*   **Плюс:** Очень быстро для больших объемов.
*   **Минус:** Если мапа не влезет в `work_mem` (RAM), база начнет сбрасывать данные на диск, и всё "умрет".

### Sort Merge Join (Сортировка и слияние)
*   **Алгоритм:**
1. Сортирует обе таблицы по ключу связи.
2. Ставит два "курсора" в начало. Если значения совпали — сдвигает оба. Если в одной таблице значение меньше — двигает курсор только в ней.
*   **Плюс:** Не требует столько памяти, сколько Hash Join, и идеален, если данные уже отсортированы индексами.
---

### Пример реального плана запроса (PostgreSQL)

Допустим, мы ищем заказ по `user_id`:
`EXPLAIN ANALYZE SELECT * FROM orders WHERE user_id = 500;`

```text
Index Scan using orders_user_id_idx on orders  (cost=0.29..8.31 rows=1 actual time=0.045..0.046 loops=1)
  Index Cond: (user_id = 500)
Planning Time: 0.088 ms
Execution Time: 0.071 ms
```
Как читать это "мясо":
* **cost=0.29..8.31**: 0.29 — цена получения первой строки, 8.31 — цена получения всех строк. (Те самые попугаи).
* **rows=1**: БД ожидает найти 1 строку (статистика).
* **actual time=0.045..0.046**: Реальное время в мс.
* **Index Cond**: Условие, по которому сработал индекс.

### Индексы и Селективность
* **Селективность**: это отношение количества уникальных значений к общему числу строк.
* **Высокая селективность (ближе к 1)**: ID, Email. Индекс работает идеально.
* **Низкая селективность (ближе к 0)**: Пол, Статус заказа (New/Paid).
* **Проблема**: Индекс по статусу Paid (которых 99%) бесполезен.

**Пошаговый процесс (Как это видит БД):**
1. **Индекс** — это отдельный файл. В нем лежат записи: `Paid -> адрес_строки_в_таблице`. Они отсортированы.
2. БД находит блок «Paid». В индексе они лежат подряд.
3. **Проблема:** Сами данные об оплате лежат в **основном файле таблицы (Heap)**. Там они разбросаны в случайном порядке (как их записывали).
4. Чтобы отдать `SELECT *`, БД должна для **каждого** «Paid» из индекса сходить в основной файл.
5. Если «Paid» — это 99% таблицы (например, 900к строк из 1000к), базе придется сделать **900 000 «прыжков»** (Random I/O) по диску.
6. **Вердикт:** Процессору быстрее прочитать всю таблицу подряд (`Seq Scan`), чем 900к раз прыгать в разные места. БД просто игнорирует индекс.

* **Решение**: Partial Index (Частичный индекс).
Мы создаем его, когда точно знаем, что искомых значений **очень мало** (высокая селективность условия).
*   **Пример:** `CREATE INDEX idx_orders_new ON orders(status) WHERE status = 'UNPAID';`  - 1% записей, которые нам реально нужно быстро находить

Если неоплаченных заказов всего 1%, индекс будет крошечным. Базе выгодно сделать 100-200 прыжков в таблицу, чем сканировать миллион строк.

---

## Классификация первичных ключей (Primary Keys)

> При проектировании таблиц важно различать происхождение и структуру ключей. Это влияет на производительность и стабильность связей.

Если мы создаем таблицу для связи пользователей и машин:
1. **id** — это суррогатный ключ (просто счетчик), цель которого — уникальность.
2. **user_id** и **car_id** — это натуральные ключи, состоящие из реальных бизнес-данных (ссылки на реальных людей и авто).
3. **(user_id, car_id)** — если мы сделаем их первичным ключом вместе, это будет **составной натуральный ключ**.

### Типы ключей по происхождению

| Характеристика | Суррогатный (Surrogate) | Натуральный (Natural) |
| :--- | :--- | :--- |
| **Происхождение** | Создается искусственно для нужд БД (ID, UUID). | Берется из предметной области (Email, VIN, ISBN). |
| **Бизнес-смысл** | Отсутствует. | Является значимой информацией. |
| **Создание** | **Автоматическое** (Identity, Sequence). | **Ручная подстановка** (из входящих данных). |
| **Стабильность** | Высокая. Не меняется при смене данных юзера. | Низкая. При смене Email придется обновлять все связи. |


### Сравнение Суррогатного и Составного подходов

**Суррогатный ID:**
* Нужно полностью изолировать связи от изменений бизнес-логики (данные меняются, но их нужно находить по стабильному ключу).
* На эту запись планируется ссылаться из других таблиц (чтобы не тащить составные FK).
* Стандарт для работы с [Hibernate](Hibernate.md#Работа-Hibernate-с-ключами-и-контекстом) (проще мапинг, не нужно создавать дополнительных классов).

**Составной ключ:**
* Технические ID нестабильны, пересоздаются или различаются в разных базах — связка натуральных полей, это единственный способ надежно идентифицировать запись.
* В простых "тупиковых" таблицах связей, на которые никто не ссылается. Экономия места на диске и в RAM (нет лишней колонки `id` и лишнего индекса по ней).

#### Пример: Уникальность на уровне структуры
Без составного ключа или UNIQUE-индекса в таблицу можно вставить дубликаты, которые сломают логику "одна машина — один юзер":
* `INSERT INTO user_car (id, user_id, car_id) VALUES (1, 10, 5);`
* `INSERT INTO user_car (id, user_id, car_id) VALUES (2, 10, 5);` — **Дубликат**, хотя технические ID разные.
  Составной PK сделает вставку второй строки невозможной.

#### Пример: Возможность ссылаться (Проблема Foreign Key)
Представим таблицу **Insurance** (Страховка) для связки "Юзер-Машина".
* **С суррогатным ID:** Нужна всего одна колонка-ссылка: `SELECT * FROM insurance WHERE user_car_id = 1;`.
* **С составным ключом:** Придется хранить и передавать оба поля: `SELECT * FROM insurance WHERE user_id = 10 AND car_id = 5;`. Это усложняет SQL и раздувает индексы.

#### Пример из рабочей практики: Когда суррогатный ID подвел
**Ситуация:** В приложении идентификаторы объектов постоянно удалялись и пересоздавались логикой. При миграции между базами (Dev/Prod) суррогатные ID одной и той же сущности различались.
**Проблема:** Приложение не могло идентифицировать уже существующую связь по `id`, считало её новой и плодило дубликаты одной и той же записи по бизнес-логике.
**Решение:** Использование **составного ключа** на основе бизнес-параметров. База сама гарантирует: если такая связка данных уже была — вторая не вставится. Это позволило использовать логику **Upsert**, опираясь на реальные данные, а не на случайные числа ID.

---

## Управление типом связи через ограничения (Constraints)

Промежуточная таблица (Join Table) не всегда означает связь "Многие-ко-многим". Тип связи зависит от того, на какие колонки наложены ограничения уникальности.

### Как превратить Many-to-Many в One-to-Many
Представим таблицу `user_car (user_id, car_id)`.

* **Связь Many-to-Many:**
  `PRIMARY KEY (user_id, car_id)` или `UNIQUE (user_id, car_id)`.
  *Позволяет:* Юзеру 1 иметь Машину 10, а Юзеру 2 — ту же Машину 10.

* **Связь One-to-Many (Одна машина — один владелец):**
  `UNIQUE (car_id)`.
  *Гарантирует:* Машина 10 может появиться в таблице только **один раз**. Следовательно, у неё может быть только один владелец.

### Типичные ошибки при проектировании
Частая ошибка — наложение уникальности на **пару** полей (`user_id`, `car_id`), когда по бизнесу требуется ограничить только **одно** из них.

**Пример ошибки:**
Если мы хотим, чтобы у машины был один хозяин, но пишем `UNIQUE (user_id, car_id)`, база пропустит:
1. `user_id: 1, car_id: 10`
2. `user_id: 2, car_id: 10` -- **Ошибка бизнес-логики**, но база считает это уникальной связкой.

**Правильное решение:**
Наложение `UNIQUE` (или `PRIMARY KEY`) строго на ту колонку, которая должна быть уникальной в рамках связи. В нашем случае это `car_id`.

### Избыточность ограничений (PK vs UNIQUE)
При проектировании важно избегать дублирования индексов.
*   **Первичный ключ (Primary Key)** автоматически создает уникальный индекс на указанные колонки и запрещает в них `NULL`.
*   Если вы уже объявили `PRIMARY KEY (user_id, car_id)`, создавать отдельно `UNIQUE (user_id, car_id)` **не нужно**. Это создаст два идентичных индекса, что замедлит операции вставки (`INSERT`) и обновления (`UPDATE`), так как базе придется обновлять обе структуры.

### Самый лаконичный способ One-to-Many
Если по условию задачи машина всегда принадлежит только одному человеку, самым эффективным решением будет сделать **`car_id` первичным ключом** таблицы связей:

`ALTER TABLE user_car ADD PRIMARY KEY (car_id);`

Это решение:
1.  **Бизнес-логика:** Гарантирует, что машина не привяжется к двум юзерам (уникальность).
2.  **Целостность:** Запрещает пустые значения (NOT NULL).
3.  **Производительность:** Создает минимально необходимый индекс для поиска владельца по машине.

---

## Выбор стратегии хранения связи: Column vs Join Table

При проектировании связи One-to-Many (Один ко многим) выбор между Foreign Key в колонке и отдельной Join Table — это компромисс между простотой и масштабируемостью.

### Foreign Key в колонке (Классический подход)
*   **Плюсы:** Максимальная простота. Меньше джоинов в запросах (высокая скорость чтения).
*   **Минусы:**
*   **Разреженность (NULLs):** Если связь есть не у всех записей, таблица и индексы растут впустую.
*   **Блокировки:** На живой базе `ALTER TABLE` для добавления колонки может заблокировать таблицу на чтение/запись.
*   **Нагрузка на запись:** База тратит ресурсы на проверку целостности (FK) при каждой вставке.

### Промежуточная таблица (Join Table)
*   **Плюсы:**
*   **Чистота (Density):** Хранятся только существующие связи. Никаких NULL.
*   **Гибкость:** Позволяет легко добавить атрибуты связи (дата покупки, цена) или сменить тип связи на Many-to-Many.
*   **Шардирование:** Таблицу связей можно вынести на отдельный инстанс (шард) независимо от основных таблиц.
*   **Минусы:** Лишний JOIN при выборке данных.

### Инсайды Highload-разработки
На проектах с миллионами пользователей архитектурные решения часто отличаются от "учебниковых":
1. **Отказ от Foreign Key:** Для обеспечения максимального быстродействия на запись констрейнты FK часто не создаются. Целостность гарантируется на уровне бизнес-логики приложения (сервисов).
2. **Индексы как налог:** Каждый индекс ускоряет поиск, но замедляет запись. В таблицах связей мы стараемся держать только необходимый минимум индексов.
3. **Безопасные миграции:** Использование Join Table позволяет вносить изменения в структуру связей, не рискуя стабильностью основных тяжелых таблиц (User, Car).

---

## Шардирование (Sharding)

**Шардирование** — это стратегия «разделяй и властвуй». Вместо того чтобы покупать один супер-дорогой сервер, мы распределяем данные между несколькими обычными серверами. Каждая часть базы (шард) содержит только подмножество данных.

### Как это работает (Пример с пользователями)
Представь, что у тебя 100 миллионов пользователей. В одну таблицу они не влезают. Мы ставим два сервера:
* **Шард №1:** Хранит пользователей с ID от 1 до 50 000 000.
* **Шард №2:** Хранит пользователей с ID от 50 000 001 до 100 000 000.

Когда приходит запрос `SELECT * FROM users WHERE id = 10`, приложение идет сразу на Шард №1.

### Почему Join Table удобнее при шардировании?
Представим ситуацию Highload-проекта: данных стало так много, что они не влезают на один сервер. Мы решаем разделить их:
*   **Сервер А:** Хранит таблицу `Users`.
*   **Сервер Б:** Хранит таблицу `Cars`.

#### Проблема Foreign Key в колонке:
Если `user_id` (внешний ключ) лежит прямо в таблице `Cars` на **Сервере Б**, база данных сталкивается с техническим тупиком. При вставке новой машины база должна проверить: «А существует ли такой пользователь?».
*   **Сетевой барьер:** Механизм Foreign Key в классических РСУБД (PostgreSQL, MySQL) работает только в рамках **одного физического сервера**. База на Сервере Б не может «сходить по сети» на Сервер А, чтобы проверить наличие юзера.
*   **Итог:** Физический Foreign Key становится невозможным. Целостность данных теряется, и её приходится проверять только кодом в Java.

#### Преимущество Join Table (Таблица связей):
При использовании промежуточной таблицы `user_car`, мы можем вынести её на **Сервер В** (координатор связей).
1.  **Автономность:** Таблицы `Users` и `Cars` остаются «чистыми» и независимыми. Они ничего не знают о связях друг друга на уровне схемы.
2.  **Масштабируемость:** Если количество связей вырастет до миллиардов, мы сможем шардировать (разделить) саму таблицу `user_car` отдельно от таблиц пользователей и машин.
3.  **Гибкость:** Мы можем хранить таблицу связей на самом быстром железе (например, в RAM-диске), обеспечивая мгновенный поиск владельцев, в то время как тяжелые данные (профили с фото) будут лежать на дешевых дисках.

### Плюсы и Минусы Шардирования

| Плюсы | Минусы |
| :--- | :--- |
| **Бесконечный рост:** Можно добавлять новые сервера по мере роста нагрузки. | **Сложность JOIN-ов:** Нельзя «джойнить» таблицы, лежащие на разных серверах (приходится склеивать данные в Java-коде). |
| **Отказоустойчивость:** Если один сервер (шард) выйдет из строя, остальные данные будут доступны. | **Транзакции:** Распределенные транзакции (между серверами) работают крайне медленно и сложно. |
| **Производительность:** Каждый сервер работает со своим маленьким индексом, что быстрее, чем один гигантский. | **Сложность миграции:** Процесс «перешардирования» (перераспределения данных) — это тяжелая и долгая операция. |

**Вердикт:** Для монолитных приложений на одном сервере Join Table — это лишнее усложнение. Но для архитектуры Highload — это необходимый инструмент для обеспечения гибкости и возможности горизонтального масштабирования.

---

## Работа с последовательностями (Sequences)

**Sequence** — это независимый объект в базе данных, предназначенный для генерации уникальных числовых значений (обычно для Primary Keys).

### Проблема рассинхронизации (Duplicate Key Error)
Типичный баг: база данных выдает ошибку уникальности при вставке, хотя визуально ID должен быть свободен.

* **Причина:** Прямая вставка в таблицу в обход генератора `INSERT INTO users (id, name) VALUES (9, 'Admin')`. База запишет ID=9, но объект Sequence об этом не узнает. Он продолжит выдавать 5, 6, 7... и на попытке выдать 9-ку "споткнется" об уже существующую запись.
* **Как починить (PostgreSQL):** Нужно принудительно синхронизировать сиквенс с данными в таблице:
  `SELECT setval('users_id_seq', (SELECT max(id) FROM users));`
  Эта команда выставляет текущее значение сиквенса равным максимальному ID в таблице.

### Параметры настройки Sequence
При создании или изменении сиквенса можно задать его "поведение":

* **START WITH:** Начальное значение. Позволяет зарезервировать первые N значений под системные нужды.
* **INCREMENT BY:** Шаг приращения. По умолчанию 1. Если установить 100, сиквенс будет выдавать `1, 101, 201...`, создавая свободные промежутки ("люфт") в 99 ID между записями.
* **MINVALUE / MAXVALUE:** Границы генерации.
* **CACHE:** Позволяет базе заранее выделить группу чисел в память. Это ускоряет работу: если шаг большой, приложение может брать пачку ID и не дергать базу на каждый `INSERT`. Однако при падении сервера "закэшированные" числа будут потеряны (появятся пропуски в ID).

---

## Сравнение суррогатных ключей: BIGINT против UUID

Выбор типа ключа определяет, насколько легко будет масштабировать систему в будущем и насколько быстро будут работать индексы.

### 1. Что такое UUID / GUID?
**UUID (Universally Unique Identifier)** — это 128-битный идентификатор, гарантирующий уникальность в масштабах всей компьютерной системы (и даже мира) без обращения к центральному серверу.
*   **Внешний вид:** 32 шестнадцатеричные цифры, разделенные дефисами (например, `550e8400-e29b-41d4-a716-446655440000`).
*   **GUID (Globally Unique Identifier):** Термин-синоним, чаще используемый в экосистеме Microsoft. Это реализация того же стандарта.

### Сравнение характеристик

| Характеристика | BIGINT (8 байт)                                                                  | UUID (16 байт)                                                                                                                                                                                                                                                                     |
| :--- |:---------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Генерация** | Только БД (Sequence/Identity). Требует сетевого запроса к базе.                  | Можно генерировать в коде (Java/JS) без участия БД. В распределенных системах (микросервисах) это критично: если у тебя 10 серверов создают заказы, им не нужно ждать ответа от одного общего сиквенса в БД, чтобы получить ID. Коллизии (совпадения) UUID практически невозможны. |
| **Производительность** | **Высокая.** Данные растут последовательно, индекс не фрагментируется. | **Ниже.** Классический UUID (v4) — это случайная строка. При вставке в B-Tree индекс базе приходится постоянно перестраивать дерево в разных местах, что дико замедляет запись (Random I/O). Целые числа всегда растут в конец, что очень эффективно                               |
| **Безопасность** | Низкая. Если  ссылка ://site.com, злоумышленник может просто перебрать 124, 125. | Высокая. Угадать следующий ID невозможно.                                                                                                                                                                                                                                          |
| **Размер** | Компактный. Занимает меньше места в RAM и на диске. BIGINT — 8 байт | Громоздкий. Занимает 16 байт. Индексы по UUID растут в 2-4 раза быстрее.                                                                                                                                                |
| **Идемпотентность** | **Сложно.** Чтобы отправить повторный запрос на создание, нужно сначала спросить у базы "какой следующий ID?". | **Идеально.** Клиент сам генерирует UUID и отправляет его в заголовке `Idempotency-Key`. База просто не создаст запись, если такой ID уже есть. |
| **Объединение баз** | **Проблема.** При слиянии двух таблиц (например, из разных регионов) ID 1, 2, 3... неизбежно совпадут. | **Просто.** Записи из разных баз гарантированно не перепутаются благодаря глобальной уникальности. |

### Когда что выбирать?

**Выбирай BIGINT, если:**
* У тебя монолитное приложение и одна база данных.
* Важна максимальная скорость вставки (High throughput).
* Нужно экономить место на диске и в индексах.

**Выбирай UUID, если:**
* У тебя **микросервисы** или шардированная БД. Нужно генерировать ID на клиенте/сервере так, чтобы они гарантированно не совпали с ID из другой базы.
* Нужно скрыть от пользователя количество записей (чтобы по ID нельзя было понять, что это 10-й заказ в магазине).
* Ты используешь **Offline-first** приложения (когда телефон создает запись без интернета и позже синхронизирует её с базой).
* Ты планируешь **слияние баз данных** или синхронизацию данных из разных источников.


### Решение проблемы фрагментации UUID
Если очень нужен UUID, но пугает медленная вставка, используют **UUID v7** (Time-based). Он содержит в себе метку времени в начале, поэтому новые UUID всегда больше старых. Это позволяет базе вставлять их в конец индекса почти так же быстро, как обычные числа.

---
